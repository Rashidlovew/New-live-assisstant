let mediaRecorder;
let audioChunks = [];
let isRecording = false;

const statusDiv = document.getElementById("status");
const audioPlayback = document.getElementById("audioPlayback");

async function startRecording() {
  if (isRecording) return;
  isRecording = true;
  statusDiv.innerText = "ðŸ”´ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„...";

  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  mediaRecorder = new MediaRecorder(stream);

  audioChunks = [];
  mediaRecorder.ondataavailable = (e) => {
    if (e.data.size > 0) audioChunks.push(e.data);
  };

  mediaRecorder.onstop = async () => {
    statusDiv.innerText = "ðŸ“¤ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©...";

    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
    const formData = new FormData();
    formData.append('file', audioBlob, 'recording.webm');

    try {
      const transcribeRes = await fetch("/transcribe", {
        method: "POST",
        body: formData
      });

      const transcribeData = await transcribeRes.json();
      console.log("ðŸ“ Ø§Ù„Ù†Øµ:", transcribeData.text); // Ù„Ù„ØªØ£ÙƒØ¯

      // âœ… Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Øµ Ù…Ù† transcribeData.text ÙˆÙ„ÙŠØ³ reply
      const speakRes = await fetch("/speak", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text: transcribeData.text })
      });

      const speakBlob = await speakRes.blob();
      const audioUrl = URL.createObjectURL(speakBlob);

      audioPlayback.src = audioUrl;
      audioPlayback.play();
      statusDiv.innerText = transcribeData.text;

    } catch (error) {
      console.error("âŒ Error:", error);
      statusDiv.innerText = "Ø­Ø¯Ø« Ø®Ø·Ø£. Ø­Ø§ÙˆÙ„ Ù…Ø¬Ø¯Ø¯Ù‹Ø§.";
    } finally {
      isRecording = false;
    }
  };

  mediaRecorder.start();
  setTimeout(() => mediaRecorder.stop(), 5000);
}
